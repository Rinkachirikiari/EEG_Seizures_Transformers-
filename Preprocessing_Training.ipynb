{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import mne\n",
    "import matplotlib as plt \n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "\n",
    "# Chemin vers le dossier parent\n",
    "dossier_parent = \"C:/Users/MAREZ10/OneDrive - Université Laval/Bureau/Projet Transformers/eeg_data\"\n",
    "\n",
    "# Dictionnaire pour stocker les données MNE par sous-dossier\n",
    "donnees_par_sous_dossier = {}\n",
    "\n",
    "# Parcours des sous-dossiers\n",
    "for nom_sous_dossier in os.listdir(dossier_parent):\n",
    "    \n",
    "    chemin_sous_dossier = os.path.join(dossier_parent, nom_sous_dossier)\n",
    "    \n",
    "    if os.path.isdir(chemin_sous_dossier):\n",
    "        \n",
    "        donnees_par_sous_dossier[nom_sous_dossier] = []\n",
    "        \n",
    "        for nom_fichier in os.listdir(chemin_sous_dossier):\n",
    "            \n",
    "            if nom_fichier.endswith('.edf'):\n",
    "                \n",
    "                chemin_fichier = os.path.join(chemin_sous_dossier, nom_fichier)\n",
    "                donnees_mne = mne.io.read_raw_edf(chemin_fichier)\n",
    "                donnees_par_sous_dossier[nom_sous_dossier].append(donnees_mne)\n",
    "\n",
    "# Affichage des informations sur les données MNE\n",
    "for nom_sous_dossier, donnees_mne in donnees_par_sous_dossier.items():\n",
    "    print(f\"Sujet {nom_sous_dossier} : {len(donnees_mne)} fichiers .edf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(donnees_par_sous_dossier.keys())\n",
    "Y = list(len(elem) for elem in donnees_par_sous_dossier.values())\n",
    "\n",
    "# Création de l'histogramme\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(X,Y, color='skyblue')\n",
    "plt.xlabel('Sujets')\n",
    "plt.ylabel('Nombre d\\'enregistrements')\n",
    "plt.title('Nombre d\\'enregistrements par sujet')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotation des étiquettes sur l'axe des x pour une meilleure lisibilité\n",
    "plt.tight_layout()  # Ajustement automatique du tracé pour éviter les chevauchements\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temps d'échantillonnage - Nombre d'enregistrements n'ayant pas une durée de 1 heure par sujet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker le nombre de fichiers par sous-dossier\n",
    "nombre_par_sous_dossier = {}\n",
    "\n",
    "# Parcours des sous-dossiers\n",
    "for nom_sous_dossier, donnees_mne_liste in donnees_par_sous_dossier.items():\n",
    "    # Initialisation du compteur pour ce sous-dossier\n",
    "    cpt = 0\n",
    "    # Parcours des données MNE dans ce sous-dossier\n",
    "    for donnees_mne in donnees_mne_liste:\n",
    "        # Vérification si la durée de la donnée MNE est inférieure à la valeur donnée\n",
    "        if donnees_mne.times[-1] < 3599.99609375:\n",
    "            # Incrémentation du compteur\n",
    "            cpt += 1\n",
    "    # Stockage du nombre dans le dictionnaire\n",
    "    nombre_par_sous_dossier[nom_sous_dossier] = cpt\n",
    "\n",
    "# Affichage du nombre de fichiers qui satisfont la condition pour chaque sous-dossier\n",
    "for nom_sous_dossier, nombre in nombre_par_sous_dossier.items():\n",
    "    print(f\"Sous-dossier {nom_sous_dossier} : {nombre} fichiers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Labelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/MAREZ10/OneDrive - Université Laval/Bureau/Projet Transformers/eeg_data)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyedflib\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import mne\n",
    "from scipy.signal import welch,stft\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def extract_basic_features(signal):\n",
    "    signal = (signal - np.mean(signal)) / np.std(signal)\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    sample_entropy = np.log(np.std(np.diff(signal)))\n",
    "    fuzzy_entropy = -np.log(euclidean(signal[:-1], signal[1:]) / len(signal))\n",
    "    skewness = skew(signal)\n",
    "    kurt = kurtosis(signal)\n",
    "    return [mean, std, sample_entropy, fuzzy_entropy, skewness, kurt]\n",
    "\n",
    "def extract_advanced_features(data, fs, window_length_sec=3):\n",
    "   \n",
    "\n",
    "    # STFT\n",
    "    f, t, Zxx = stft(data, fs, nperseg=window_length_sec*fs)\n",
    "    \n",
    "    \n",
    "    power = np.mean(np.abs(Zxx)**2, axis=1)  \n",
    "\n",
    "    return power\n",
    "\n",
    "def preprocess_and_extract_features_mne_with_timestamps(file_name):\n",
    "    \n",
    "    raw = mne.io.read_raw_edf(file_name, preload=True)\n",
    "\n",
    "    \n",
    "    raw.filter(1., 50., fir_design='firwin')\n",
    "\n",
    "    #  EEG \n",
    "    raw.pick_types(meg=False, eeg=True, eog=False)\n",
    "\n",
    "    window_length = 3 \n",
    "    sfreq = raw.info['sfreq']  \n",
    "    window_samples = int(window_length * sfreq)\n",
    "\n",
    "   \n",
    "    features_with_timestamps = []\n",
    "\n",
    "   \n",
    "    for start in range(0, len(raw.times), window_samples):\n",
    "        end = start + window_samples\n",
    "        if end > len(raw.times):\n",
    "            break\n",
    "\n",
    "       \n",
    "        window_data, times = raw[:, start:end]\n",
    "        window_data = np.squeeze(window_data)\n",
    "\n",
    "        \n",
    "        timestamp = raw.times[start]\n",
    "\n",
    "        \n",
    "        for channel_data in window_data:\n",
    "            basic_features = extract_basic_features(channel_data)\n",
    "            advanced_features = extract_advanced_features(channel_data, sfreq)\n",
    "            combined_features = np.concatenate([[timestamp], basic_features, advanced_features])\n",
    "            features_with_timestamps.append(combined_features)\n",
    "\n",
    "    return np.array(features_with_timestamps)\n",
    "\n",
    "preprocess_and_extract_features_mne_with_timestamps(path+\"/chb01/chb01_03.edf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extractTarget(summary_file_path, edf_file_path):\n",
    "    \n",
    "    edf_file_name = os.path.basename(edf_file_path)\n",
    "    seizure_start_time = None\n",
    "    seizure_end_time = None\n",
    "   \n",
    "    with open(summary_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    found = False\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"File Name: \" + edf_file_name in line:\n",
    "            found = True\n",
    "        if found:\n",
    "            if \"Number of Seizures in File: 0\" in line:\n",
    "                return None, None  \n",
    "            if \"Seizure Start Time:\" in line:\n",
    "                seizure_start_time = int(line.split(\": \")[1].split(\" \")[0])\n",
    "            if \"Seizure End Time:\" in line:\n",
    "                seizure_end_time = int(line.split(\": \")[1].split(\" \")[0])\n",
    "                break  \n",
    "\n",
    "    return seizure_start_time, seizure_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def extract_data_and_labels(edf_file_path, summary_file_path):\n",
    "\n",
    "    \n",
    "    X = preprocess_and_extract_features_mne_with_timestamps(edf_file_path)\n",
    "    \n",
    "    seizure_start_time, seizure_end_time = extractTarget(summary_file_path, edf_file_path)\n",
    "    y = np.array([1 if seizure_start_time <= row[0] <= seizure_end_time else 0 for row in X])\n",
    "\n",
    "    #Time\n",
    "    X = X[:,1:]\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def load_data(subject_id,base_path):\n",
    "   \n",
    "    #edf_file_path = sorted(glob.glob(os.path.join(base_path, \"chb\"+subject_id+\".edf\"))) \n",
    "    #summary_file_path = os.path.join(base_path, \"chb\"+subject_id+\"/chb\"+subject_id+\"-summary.txt\")\n",
    "    \n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    for edf_file_path in edf_file_path:\n",
    "        X, y = extract_data_and_labels(edf_file_path, summary_file_path)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "    return all_X,all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sujet_1 = load_data('03', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sujet_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
