{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import mne\n",
    "import matplotlib as plt \n",
    "import os \n",
    "import mne\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Chemin vers le dossier parent\n",
    "dossier_parent = \"C:/Users/MAREZ10/OneDrive - Université Laval/Bureau/Projet Transformers/eeg_data\"\n",
    "\n",
    "# Dictionnaire pour stocker les données MNE par sous-dossier\n",
    "donnees_par_sous_dossier = {}\n",
    "\n",
    "# Parcours des sous-dossiers\n",
    "for nom_sous_dossier in os.listdir(dossier_parent):\n",
    "    \n",
    "    chemin_sous_dossier = os.path.join(dossier_parent, nom_sous_dossier)\n",
    "    \n",
    "    if os.path.isdir(chemin_sous_dossier):\n",
    "        \n",
    "        donnees_par_sous_dossier[nom_sous_dossier] = []\n",
    "        \n",
    "        for nom_fichier in os.listdir(chemin_sous_dossier):\n",
    "            \n",
    "            if nom_fichier.endswith('.edf'):\n",
    "                \n",
    "                chemin_fichier = os.path.join(chemin_sous_dossier, nom_fichier)\n",
    "                donnees_mne = mne.io.read_raw_edf(chemin_fichier)\n",
    "                donnees_par_sous_dossier[nom_sous_dossier].append(donnees_mne)\n",
    "\n",
    "# Affichage des informations sur les données MNE\n",
    "for nom_sous_dossier, donnees_mne in donnees_par_sous_dossier.items():\n",
    "    print(f\"Sujet {nom_sous_dossier} : {len(donnees_mne)} fichiers .edf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(donnees_par_sous_dossier.keys())\n",
    "Y = list(len(elem) for elem in donnees_par_sous_dossier.values())\n",
    "\n",
    "# Création de l'histogramme\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(X,Y, color='skyblue')\n",
    "plt.xlabel('Sujets')\n",
    "plt.ylabel('Nombre d\\'enregistrements')\n",
    "plt.title('Nombre d\\'enregistrements par sujet')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotation des étiquettes sur l'axe des x pour une meilleure lisibilité\n",
    "plt.tight_layout()  # Ajustement automatique du tracé pour éviter les chevauchements\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temps d'échantillonnage - Nombre d'enregistrements n'ayant pas une durée de 1 heure par sujet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker le nombre de fichiers par sous-dossier\n",
    "nombre_par_sous_dossier = {}\n",
    "\n",
    "# Parcours des sous-dossiers\n",
    "for nom_sous_dossier, donnees_mne_liste in donnees_par_sous_dossier.items():\n",
    "    # Initialisation du compteur pour ce sous-dossier\n",
    "    cpt = 0\n",
    "    # Parcours des données MNE dans ce sous-dossier\n",
    "    for donnees_mne in donnees_mne_liste:\n",
    "        # Vérification si la durée de la donnée MNE est inférieure à la valeur donnée\n",
    "        if donnees_mne.times[-1] < 3599.99609375:\n",
    "            # Incrémentation du compteur\n",
    "            cpt += 1\n",
    "    # Stockage du nombre dans le dictionnaire\n",
    "    nombre_par_sous_dossier[nom_sous_dossier] = cpt\n",
    "\n",
    "# Affichage du nombre de fichiers qui satisfont la condition pour chaque sous-dossier\n",
    "for nom_sous_dossier, nombre in nombre_par_sous_dossier.items():\n",
    "    print(f\"Sous-dossier {nom_sous_dossier} : {nombre} fichiers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chemin d'accès au fichier\n",
    "file_path = \"C:/Users/MAREZ10/OneDrive - Université Laval/Bureau/Projet Transformers/eeg_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_summary(file_path):\n",
    "    # Initialisation des listes pour stocker les informations\n",
    "    seizure_presence = {}\n",
    "    \n",
    "    # Chemin d'accès au fichier\n",
    "    #file_path = \"chb04-summary.txt\"\n",
    "    \n",
    "    # Ouvrir et lire le fichier\n",
    "    is_seizure = False\n",
    "    all_files_str = []\n",
    "    seizure_start = 0\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Lire chaque ligne du fichier\n",
    "        for line in file:\n",
    "            # Traiter la ligne actuelle\n",
    "            if line.strip():\n",
    "                if \"File Name:\" in line:\n",
    "                  start = len(\"File Name: \")\n",
    "                  all_files_str.append(str(line[start:len(line)-1]))\n",
    "                elif (\"Seizure\" in line) and (\"Start Time: \" in line):\n",
    "                  if line[len(\"Seizure S\")-1] == \"S\":\n",
    "                    start = len(\"Seizure Start Time: \")\n",
    "                  else:\n",
    "                    start = len(\"Seizure 1 Start Time: \")\n",
    "                  end = len(\" seconds\")+1\n",
    "                  seizure_start = int(line[start:len(line)-end])\n",
    "                elif (\"Seizure\"in line) and (\"End Time: \" in line):\n",
    "                  if line[len(\"Seizure E\")-1] == \"E\":\n",
    "                    start = len(\"Seizure End Time: \")\n",
    "                  else:\n",
    "                    start = len(\"Seizure 1 End Time: \")\n",
    "                  end = len(\" seconds\")+1\n",
    "                  seizure_end = int(line[start:len(line)-end])\n",
    "                  if not all_files_str[len(all_files_str)-1] in seizure_presence.keys():\n",
    "                    seizure_presence[all_files_str[len(all_files_str)-1]] = []\n",
    "                  seizure_presence[all_files_str[len(all_files_str)-1]].append((seizure_start, seizure_end))\n",
    "    print(\"Seizure presence init\" ,seizure_presence)\n",
    "    return seizure_presence, all_files_str\n",
    "\n",
    "\n",
    "def separate_data_intervals(file_str, seizure_presence,path):\n",
    "  # Durée de chaque intervalle en secondes (5 minutes)\n",
    "  interval_duration = 5 * 60\n",
    "\n",
    "  raw = mne.io.read_raw_edf(path + file_str)\n",
    "  #data, times = raw[:, :]\n",
    "  total_duration = raw.times[-1] # en secondes\n",
    "\n",
    "  # Nombre total d'intervalle de 10 minutes\n",
    "  num_intervals = int(total_duration / interval_duration)\n",
    "  labels = []\n",
    "  data = []\n",
    "  \n",
    "  # print(\"Seizure presence: \", seizure_presence) \n",
    "  \n",
    "  # Diviser les données en intervalles de 10 minutes\n",
    "  for i in range(num_intervals):\n",
    "      # Calculer le temps de début et de fin de chaque intervalle\n",
    "      start_time = i * interval_duration\n",
    "      end_time = (i + 1) * interval_duration\n",
    "            \n",
    "\n",
    "      # Convertir le temps en indice\n",
    "      start_idx = raw.time_as_index(start_time)\n",
    "      end_idx = raw.time_as_index(end_time)\n",
    "\n",
    "      # Extraire les données de l'intervalle\n",
    "      interval_data, interval_times = raw[:, start_idx:end_idx]\n",
    "      data.append(interval_data)\n",
    "\n",
    "      \n",
    "      if file_str in seizure_presence.keys():\n",
    "        is_seizure = False\n",
    "        for start_seizure, end_seizure in seizure_presence[file_str]:\n",
    "\n",
    "\n",
    "          if (start_seizure >= start_time and start_seizure <= end_time) or (end_seizure >= start_time and end_seizure <= end_time) or (start_seizure <= start_time and end_seizure >= end_time):\n",
    "                \n",
    "            is_seizure = True\n",
    "  \n",
    "            break\n",
    "        if is_seizure:\n",
    "          labels.append(1)\n",
    "        else:\n",
    "          labels.append(0)\n",
    "      else:\n",
    "        labels.append(0)\n",
    "  return data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_patient(file_path, patient):\n",
    "      \n",
    "    path = file_path +\"/\"+ patient + \"/\"\n",
    "    seizure_presence, all_files_str = read_summary(path+patient+\"-summary.txt\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    for file in all_files_str:\n",
    "      print(\"Reading file : \", file)\n",
    "      interval_data, label = separate_data_intervals(file, seizure_presence,path)\n",
    "      print(\"End of file\")\n",
    "      for i in range(len(interval_data)):\n",
    "        data.append(interval_data[i])\n",
    "        labels.append(label[i])\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_data_for_patient(file_path, \"chb07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 785, 1: 5}\n"
     ]
    }
   ],
   "source": [
    "oc={}\n",
    "for elem in labels:\n",
    "    oc[elem] = labels.count(elem)\n",
    "\n",
    "print(oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n",
      "(23, 76800)\n"
     ]
    }
   ],
   "source": [
    "for item in data : \n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(632, 23, 76800)\n",
      "(632,)\n",
      "(158, 23, 76800)\n",
      "(158,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'convolution' from 'c:\\\\Users\\\\MAREZ10\\\\OneDrive - Université Laval\\\\Documents\\\\GitHub\\\\EEG_Seizures_Transformers-\\\\convolution.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import convolution\n",
    "from importlib import reload\n",
    "reload(transformers)\n",
    "reload(convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Conformer(nn.Sequential):\n",
    "    def __init__(self, emb_size=40, nb_channels =23, depth=6, n_classes=2, **kwargs):\n",
    "        super().__init__(\n",
    "\n",
    "            convolution.PatchEmbedding(emb_size, nb_channels),\n",
    "            transformers.TransformerEncoder(depth, emb_size),\n",
    "            transformers.ClassificationHead(emb_size, n_classes)\n",
    "        )\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 100\n",
    "model = Conformer().cuda()\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, train_label, test_data, test_label):\n",
    "\n",
    "        \n",
    "        train_data = torch.from_numpy(train_data)\n",
    "        train_label = torch.from_numpy(train_label)\n",
    "        dataset = torch.utils.data.TensorDataset(train_data, train_label)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_data = torch.from_numpy(test_data)\n",
    "        test_label = torch.from_numpy(test_label)\n",
    "        #test_dataset = torch.utils.data.TensorDataset(test_data, test_label)\n",
    "        #test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "        test_data = Variable(test_data.type(Tensor))\n",
    "        test_label = Variable(test_label.type(LongTensor))\n",
    "\n",
    "        bestAcc = 0\n",
    "        averAcc = 0\n",
    "        num = 0\n",
    "        Y_true = 0\n",
    "        Y_pred = 0\n",
    "\n",
    "\n",
    "        for e in range(n_epochs):\n",
    "            model.train()\n",
    "            for i, (train_data, train_label) in enumerate(dataloader):\n",
    "\n",
    "                train_data = Variable(train_data.cuda().type(Tensor))\n",
    "                train_label = Variable(train_label.cuda().type(LongTensor))\n",
    "\n",
    "                tok, outputs = model(train_data)\n",
    "\n",
    "                loss = criterion(outputs, train_label) \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # test process\n",
    "            if (e + 1) % 1 == 0:\n",
    "                model.eval()\n",
    "                Tok, Cls = model(test_data)\n",
    "\n",
    "\n",
    "                loss_test = criterion(Cls, test_label)\n",
    "                y_pred = torch.max(Cls, 1)[1]\n",
    "                acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n",
    "                train_pred = torch.max(outputs, 1)[1]\n",
    "                train_acc = float((train_pred == train_label).cpu().numpy().astype(int).sum()) / float(train_label.size(0))\n",
    "\n",
    "                print('Epoch:', e,\n",
    "                      '  Train loss: %.6f' % loss.detach().cpu().numpy(),\n",
    "                      '  Test loss: %.6f' % loss_test.detach().cpu().numpy(),\n",
    "                      '  Train accuracy %.6f' % train_acc,\n",
    "                      '  Test accuracy is %.6f' % acc)\n",
    "\n",
    "                \n",
    "                num = num + 1\n",
    "                averAcc = averAcc + acc\n",
    "                if acc > bestAcc:\n",
    "                    bestAcc = acc\n",
    "                    Y_true = test_label\n",
    "                    Y_pred = y_pred\n",
    "\n",
    "\n",
    "        torch.save(model.module.state_dict(), 'model.pth')\n",
    "        averAcc = averAcc / num\n",
    "        print('The average accuracy is:', averAcc)\n",
    "        print('The best accuracy is:', bestAcc)\n",
    "        \n",
    "\n",
    "        return bestAcc, averAcc, Y_true, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 79.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_data, train_label, test_data, test_label)\u001b[0m\n\u001b[0;32m     29\u001b[0m train_data \u001b[38;5;241m=\u001b[39m Variable(train_data\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mtype(Tensor))\n\u001b[0;32m     30\u001b[0m train_label \u001b[38;5;241m=\u001b[39m Variable(train_label\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mtype(LongTensor))\n\u001b[1;32m---> 32\u001b[0m tok, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, train_label) \n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MAREZ10\\OneDrive - Université Laval\\Documents\\GitHub\\EEG_Seizures_Transformers-\\convolution.py:46\u001b[0m, in \u001b[0;36mPatchEmbedding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshallownet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojection(x)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\activation.py:514\u001b[0m, in \u001b[0;36mELU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:1564\u001b[0m, in \u001b[0;36melu\u001b[1;34m(input, alpha, inplace)\u001b[0m\n\u001b[0;32m   1562\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1564\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.42 GiB is allocated by PyTorch, and 79.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train(train_data, train_labels, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
